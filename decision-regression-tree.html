<!DOCTYPE html>
<html lang="[en]">
<head>
	<link rel="stylesheet" type="text/css" href="/theme/css/style.css">
	<!--<link rel="stylesheet/less" type="text/css" href="/theme/css/style.less">-->
	<!--<script src="/theme/js/less.js" type="text/javascript"></script>-->
	<link rel="stylesheet" type="text/css" href="/theme/css/pygments.css">
	<link rel="stylesheet" type="text/css" href="/theme/css/ydSetting.css">
	<link href='//fonts.googleapis.com/css?family=Open+Sans:800,400,300|Inconsolata' rel='stylesheet' type='text/css'>

	<link href="aady5566.github.io/" type="application/atom+xml" rel="alternate" title="YD's Blog ATOM Feed" />


		<title>YD's Blog</title>
		<meta charset="utf-8" />
</head>
<body>
	<section id="sidebar">
		<figure id="user_logo">
            <a href=""><div class="logo">&nbsp;</div></a>
		</figure>

		<div class="user_meta">
            <h1 id="user"><a href="" class="">YD</a></h1>
			<h2></h2>
			<p class="bio">lives in a cave.</p>
			<ul>
					<li><a href="http://aady5566.bitbucket.org/" target="_blank">@_yd</a></li>
					<li><a href="https://tw.linkedin.com/in/yd-huang-735358aa" target="_blank">linkedin</a></li>
					<li><a href="https://github.com/aady5566" target="_blank">github</a></li>
					<li><a href="mailto:ydhuang@ntu.edu.tw" target="_blank">mail</a></li>
			</ul>
		</div>
		<footer>
			<address>
				Powered by <a href="http://pelican.notmyidea.org/">Pelican</a>,
		                theme by <a href="https://github.com/wting/pelican-svbtle">wting</a>.
			</address>
		</footer>
	</section>

	<section id="posts">
	<header>
		<h1>YD's blog</h1>
		<h3>Posted 三 27 4月 2016</h3>
	</header>
	<article>
		<h1 id="title">
			<a href="/decision-regression-tree.html" rel="bookmark"
				title="Permalink to Decision, Regression tree">Decision, Regression tree</a>
		</h1>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ['\\(','\\)'] ]
  }
});
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-77164531-1', 'auto');
ga('send', 'pageview');

</script>

<p>Decision tree 與 Regression tree的概念都是建一顆樹(e.g. binary tree, minimize the traning error in each leaf)且都是<a href="http://aady5566.github.io/supervised-vs-unsupervised-learning.html">Supervised learning</a>。差別在於資料形態的不同：  </p>
<ul>
<li>Decision tree: $x_i \in \mathbb{R}, y_i \in $ { $ Finite~Set $ }$ $</li>
<li>Regression tree: $x_i \in \mathbb{R}, y_i \in \mathbb{R}$</li>
</ul>
<p>Decision tree會有類別變項：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/decisiontree.png" width="400" height="400" />  </p>
<p>利用不斷的二分法將區域切出來。再依照該區的類別採多數決(majority vote of classification)進行分類。如下圖：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/decisiontree.png" width="400" height="400" />  </p>
<p>但因為採多數決，所以會有區域誤判的可能(下文會提到Impurity Measures來衡量誤判率)。</p>
<p>先前提到Regression tree 和 Decision tree的差別為資料形態的不同，最簡單的例子即 $x$, $y$ 皆為實數。實際做法會先將 $x$切出好幾個區域(為決策的判斷)，接著在各個區域內得出預測值<br />
 $\hat{y}$， 此預測值是來自該區依最小平方法得到的: $\bar{y} = min\sum_{i \in \mathbb{R}_k}(\hat{y}-y_i)^2$，即該區的平均值：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/regressiontree.png" width="400" height="400" />   </p>
<p>因此得到的預測值 $y$ 即為該區的 $\bar{y}$：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/regressiontree2.png" width="400" height="400" />  </p>
<p>那我們要如何擴充樹葉呢(也就是圖中的每個節點)?
以三維空間舉例：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/cube.png" width="400" height="400" />  </p>
<p>如果要長regression tree，首先選定一個維度 $j=1$，根據資料點找出點 $s$ 使得 $ \sum_{x_{ij}&gt;s,x_i \in \mathbb{R}_j}(\hat{y}-y_i)^2$  </p>
<p>加上  </p>
<p>$\sum_{x_{ij} \leq s,x_i \in \mathbb{R}_j}(\hat{y}-y_i)^2$最小，根據這個原則重複步驟就可以做出一堆的sub-region。<br />
那到底要切到何時呢?有兩種標準：  </p>
<ul>
<li>Stop when one points in the (sub-)region</li>
<li>Only consider splits resulting in the (sub-)region with $\geq 5$</li>
</ul>
<p>同理，要長decision(classification) tree也是依照類似的方法，以二維平面解釋：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/decisiontree3.png" width="400" height="400" />  </p>
<p>先定義一下，$E_R$: misclassified by a majority vote in the (sub-)region，以此圖為1/3，算法為 $min \frac{1}{N_{R_j}}\sum_{x_i \in \mathbb{R}_j} I(y_i \neq y) ,~y= ~${$  Finite~Set  $}$, N_R=~ ${$  i:x_i \in \mathbb{R_j}  $}  </p>
<p>若以三維空間說明的話，則是讓切出的兩區的 $E_{R_j}(j,s)+E_{R_j}'(j,s)$ 最小化：  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/cube2.png" width="400" height="400" />  </p>
<hr />
<p><h3>Impurity Measures</h3>  </p>
<p>前述提到分類誤判，衡量一個模型的分類誤判率有三種常見的方式：  </p>
<ul>
<li>$E_R$: $P_R(Y), ~Y= ~${$  Classification Finite~Set  $}</li>
<li>$H_R$ (Entropy): $-\sum_{y \in Y}(P_R(Y) \cdot \log{P_R(Y)})$</li>
<li>$G_R$ (Gini's index): $\sum_{y \in Y}(P_R(Y) \cdot (1-P_R(Y)))$</li>
</ul>

		<div id="article_meta">
				Category:
					<a href="/category/stat.html">Stat</a>
		</div>
	</article>

	<footer>
		<a href="/" class="button_accent">&larr;&nbsp;&nbsp;&nbsp;Back to blog</a>
	</footer>


	</section>

</body>
</html>