<!DOCTYPE html>
<html lang="[en]">
<head>
	<link rel="stylesheet" type="text/css" href="http://aady5566.github.io/theme/css/style.css">
	<!--<link rel="stylesheet/less" type="text/css" href="/theme/css/style.less">-->
	<!--<script src="/theme/js/less.js" type="text/javascript"></script>-->
	<link rel="stylesheet" type="text/css" href="http://aady5566.github.io/theme/css/pygments.css">
	<link rel="stylesheet" type="text/css" href="http://aady5566.github.io/theme/css/ydSetting.css">
	<link href='//fonts.googleapis.com/css?family=Open+Sans:800,400,300|Inconsolata' rel='stylesheet' type='text/css'>

	<link href="aady5566.github.io/" type="application/atom+xml" rel="alternate" title="YD's Blog ATOM Feed" />


		<title>YD's Blog</title>
		<meta charset="utf-8" />
</head>
<body>
	<section id="sidebar">
		<figure id="user_logo">
            <a href="http://aady5566.github.io"><div class="logo">&nbsp;</div></a>
		</figure>

		<div class="user_meta">
            <h1 id="user"><a href="http://aady5566.github.io" class="">YD</a></h1>
			<h2></h2>
			<p class="bio">lives in a cave.</p>
			<ul>
					<li><a href="http://aady5566.bitbucket.org/" target="_blank">@_yd</a></li>
					<li><a href="https://tw.linkedin.com/in/yd-huang-735358aa" target="_blank">linkedin</a></li>
					<li><a href="https://github.com/aady5566" target="_blank">github</a></li>
					<li><a href="mailto:ydhuang@ntu.edu.tw" target="_blank">mail</a></li>
			</ul>
		</div>
		<footer>
			<address>
				Powered by <a href="http://pelican.notmyidea.org/">Pelican</a>,
		                theme by <a href="https://github.com/wting/pelican-svbtle">wting</a>.
			</address>
		</footer>
	</section>

	<section id="posts">
	<header>
		<h1>YD's blog</h1>
		<h3>Posted 二 26 4月 2016</h3>
	</header>
	<article>
		<h1 id="title">
			<a href="http://aady5566.github.io/k-nearest-neighbor-algorithms-knn.html" rel="bookmark"
				title="Permalink to K-Nearest Neighbor algorithms (KNN)">K-Nearest Neighbor algorithms (KNN)</a>
		</h1>
		<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ['\\(','\\)'] ]
  }
});
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-77164531-1', 'auto');
ga('send', 'pageview');

</script>

<p>如果我們有一筆資料 $(x_1,y_1),...,(x_n,y_n)$，  </p>
<p>且 $x_i \in \mathbb{R}^2, y_i \in {0,1}$ (即 $x_i=(x_1,x_2)$為二維的自變項以及 $y_i = 0 ~or~ 1$的依變項)。如圖所示：
<img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/knn.png" width="400" height="400" />  </p>
<p>橫軸為 $x_1$、縱軸為 $x_2$、藍色和紅色分別為已知的分類(0或1)。圖中的黃點並非髒污，而是要進行分類的 $x$。  </p>
<p>KNN的概念其實很就是去算點與點之間的距離，距離越近表示類型越像(和<a href="http://aady5566.github.io/k-means.html">K-means</a>有異曲同工之妙，但注意，KNN是屬於<a href="http://aady5566.github.io/supervised-vs-unsupervised-learning.html">Supervised learning</a>，這點和K-means不同)。
若 $k=1$，則是根據離黃點最近的「1個點」之分類為分類; $k=3$則是根據離黃點最近的「3個點」之分類為分類並採取多數決(majority vote of k nearest)。以下圖為例：
<img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/knn2.png" width="400" height="400" />  </p>
<p>此例為 $k=3$，意即離黃點最近的三個點分別為1,1,0的分類，依照多數決應將黃點分類為類別1。  </p>
<p>若將KNN寫成公式的話：<br />
<div style="font-size:150%">$d(x_i,x_j)=\sqrt{\sum_{k=1}^{d}(x_{ik}-x_{jk})^2}, x_i=(x_{i1},...,x_{id})$</div>  </p>
<p><img class='shaped' src="https://raw.githubusercontent.com/aady5566/aady5566.github.io/master/pic/knndemo.png" width="400" height="400" />  </p>
<p>此為 $k=1$的例子，已知紅點距離最近的點為藍色，因此判斷紅色的分類為1。有興趣的話可以參考下列R code。可以自己調整參數玩玩看</p>
<pre>
# K-Nearest Neighbor classification ---------------------------------------
library(data.table)
library(ggplot2)
#training data
#simplify to two-dimensional real numbers
dt <- data.table(x1=sample(1:10,30,replace=T),x2=sample(1:10,30,replace=T),label=as.factor(sample(0:1,30,replace=T)))

#new x^(2)=(x1,x2)
newX=c(8,7)
k=1 #k could be a odd number

#find out the label of k smallest distances of x
nearestLabels <- dt$label[!is.na(match(sqrt((newX[1]-dt$x1)^2+(newX[2]-dt$x2)^2),sort(sqrt((newX[1]-dt$x1)^2+(newX[2]-dt$x2)^2))[1:k]))]

#majority vote of k nearest points
tb <- as.data.table(table(nearestLabels))
predictLabel <- paste("predict: ",tb$nearestLabels[match(max(tb$N),tb$N)],sep='')
predict.dt <- data.table(x1=newX[1],x2=newX[2],label=predictLabel)

#bind preditVal to original dt
dt <- rbind(predict.dt,dt)

#plot the outcome
qplot(x1,x2,colour=label,data=dt)

</pre>

		<div id="article_meta">
				Category:
					<a href="http://aady5566.github.io/category/stat.html">Stat</a>
		</div>
	</article>

	<footer>
		<a href="http://aady5566.github.io/" class="button_accent">&larr;&nbsp;&nbsp;&nbsp;Back to blog</a>
	</footer>


	</section>

</body>
</html>